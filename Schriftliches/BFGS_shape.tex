\documentclass[bibliography=totoc,12pt,a4paper]{scrartcl}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{enumerate}% schicke Nummerierung
\usepackage{graphicx}
\usepackage[english, ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{bigdelim}
\usepackage{multirow}
\usepackage{dsfont}
\usepackage[colorlinks=true,linkcolor=black, citecolor=black]{hyperref}
\usepackage{cite}
\usepackage[nottoc]{tocbibind}
\usepackage{empheq}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{lipsum}
\usepackage{tikz,pgfplots}
\usepackage{nicefrac}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{matrix}
\geometry{a4paper,left=40mm,right=30mm, top=5cm, bottom=5cm} 

\def\@biblabel#1{\textcolor{red}{[#1]}}

\newtheoremstyle{linebreak}   % name
{3pt}                         % Space above
{3pt}                         % Space below
{}                            % Body font
{}                            % Indent amount 1
{\bfseries}                   % Theorem head font
{\newline}                    % Punctuation after theorem head
{.5em}                        % Space after theorem head 2
{}                            % Theorem head spec (can be left empty, meaning ‘normal’)
%\theoremstyle{linebreak}
\newtheoremstyle{exampstyle}
  {\topsep} % Space above
  {\topsep} % Space below
  {} % Body font
  {} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  {.5em} % Space after theorem head
  {} % Theorem head spec (can be left empty, meaning `normal')
\theoremstyle{exampstyle}
\newtheorem{defi}{Definition}%[chapter]
\newtheorem{satz}[defi]{Satz}
\newtheorem{theorem}[defi]{Theorem}
\newtheorem{propo}[defi]{Proposition}
\newtheorem{lemma}[defi]{Lemma}
\newtheorem{cor}[defi]{Korollar}
\newtheorem{bem}[defi]{Bemerkung}
\newtheorem{bsp}[defi]{Beispiel}
\newtheorem{folg}[defi]{Folgerung}
%bemerkungen oder Fließtext???
\numberwithin{equation}{section} 
 \newcommand{\newln}{\\&\quad\quad{}}
 \setlength\parindent{0pt}

\renewenvironment{abstract}
 {\small
  \begin{center}
  \bfseries \abstractname\vspace{-.5em}\vspace{0pt}
  \end{center}
  \list{}{%
    \setlength{\leftmargin}{12mm}% <---------- CHANGE HERE
    \setlength{\rightmargin}{\leftmargin}%
  }%
  \item\relax}
 {\endlist}




\begin{document}

\title{Quasi-Newton Methoden in der Formoptimierung}

\author{Daniel Luft \\ Prof. Dr. V. Schulz}

  \pagestyle{empty}

  % Ab sofort Seitenzahlen in der Kopfzeile anzeigen
  \pagestyle{headings}
  
\selectlanguage{ngerman}

\section{BFGS-Algorithmus in der Formoptimierung}
\subsection{Shape Spaces und Formgradienten}
\colorbox{red}{habe ich sicher das Kapitel zu Rn BFGS? falls nicht korrigiere text}
\colorbox{red}{soll ich 2 dimensional oder beliebig dimensional machen? habe hier bisschen von beidem...}
\colorbox{red}{ statt jedes mal die voraussetzunge zu überprüfen, also zsmhgd, beschr,... nutze lieber vllt einfach die Definition von regulärem Gebiet aus anderem Chapter?}
\colorbox{red}{Notation: einmal Gradient H, dann später U... mache das einheitlich!}
\colorbox{red}{erkläre, dass broyden symm rank 1 vllt nicht schlecht ist, falls großer kern der hesse bei optimierung entsteht und p.d. nicht gewährleistet ist.}
Nachdem wir in die Grundlagen der Formoptimierung und des BFGS-Algorithmus im endlich-dimensionalen eingeführt haben, möchten wir nun in diesem Abschnitt beide Bereiche zusammenführen und die endlich-dimensionalen BFGS-Updates in den Kontext von Formen abstrahieren. Dies ist nicht ohne weiteres möglich, da a priori nicht klar ist, wie Gradienten von Formen definiert werden sollen, insbesondere deshalb, weil wir uns in unendlich-dimensionalen Shape-space befinden. Erschwert wird dies weiter dadurch, dass, wie eingangs bemerkt, keine natürliche Vektorraumstruktur auf dem betrachteten Shape-space vorhanden ist. Ziel dieses Abschnittes wird es sein zunächst die Wahl eine geeigneten Metrik im Sinne der Riemannschen Geometrie zu wählen, wodurch die Definition eines Gradienten überhaupt erst möglich wird. Im Abschnitt über BFGS-Methoden im $\mathbb{R}^n$ haben wir zur Darstellung solcher Gradienten stets stillschweigend die euklidische Metrik vorausgesetzt. Diese lässt sich offensichtlich nicht einfach im Shape-setting verwenden. Anschließend übertragen wir den BFGS-Algorithmus in das Shape-setting. In diesem Abschnitt halten wir uns vorallem an \cite{bfgs1}, sowie an \cite{shape_space} und \cite{bfgs2}.

Zunächst definieren wir, was wir unter dem Raum aller Formen verstehen, vgl. \cite{bfgs1}. Hierzu bleiben wir in zwei Dimensionen, da hier schon die wesentlichen Elemente und Zusammenhänge klar werden. Prinzipiell ist ein betrachten von höherdimensionalen Objekten auch möglich, sofern die zugrundeliegende Topologie der Formen beachtet wird.

\begin{defi}[Shape-space für den $\mathbb{R}^2$]
Bezeichne mit $\text{Emb}(S^1, \mathbb{R}^2)$ die Menge aller $C^\infty$ Einbettungen von $S^1$ in den $\mathbb{R}^2$, und mit $\text{Diff}(S^1)$ die Menge aller Diffeomorphismen von $S^1$ in sich selber. Dann heißt der Quotientenraum
\begin{align*}
	B_e(S^1,\mathbb{R}^2) := \text{Emb}(S^1, \mathbb{R}^2) / \text{Diff}(S^1)
\end{align*}
\textit{Shape-space} für den $\mathbb{R}^2$.
\end{defi}

Man sieht, dass die Elemente von $B_e(S^1,\mathbb{R}^2)$ Äquivalenzklassen sind. In ihnen sind jeweils unter anderem Umparametrisierungen der selben geschlossenen $C^\infty$-Kurven $c: \mathbb{R} \rightarrow \mathbb{R}^2$ enthalten. Das bedeutet, dass ein Punkt in $B_e(S^1,\mathbb{R}^2)$ als eine geschlossene, geometrische Kurve im $\mathbb{R}^2$ interpretiert werden kann. Betrachtet man nun eine über eine beschränkte Menge $\Omega\subset\mathbb{R}^2$ mit Lipschitz-Rand definierte Hold-all-Domain, so lassen sich Ränder $\partial\Omega_2$ von kompakten, beschränkten, zusammenhängenden Mengen $\Omega_2\subset \Omega$ mit $C^\infty$-Rand genau mit solchen geschlossenen Kurven identifizieren. Zudem gilt außerdem, dass $B_e(S^1,\mathbb{R}^2)$ eine Mannigfaltigkeit bildet, siehe \cite{bfgs1}, was wesentlich von der Glattheit der Einbettungen abhängt.

Wir fahren fort mit unserer Konstruktion, und geben hier eine Darstellung des Tangentialbündels auf $B_e(S^1,\mathbb{R}^2)$. Da wir hier explizit die Strukturen des $\mathbb{R}^2$ und $B_e(S^1,\mathbb{R}^2)$ für die Darstellung der Tangentialräume verwenden, handelt es sich bei unserer Definition um zu den üblichen Tangentialräumen der Differentialgeometrie isomorphe Objekte. Für eine Definition der klassischen Tangentialräume, sowie eine tiefgreifende Einführung in die Differentialgeometrie, empfehlen wir \cite{LeeDGEO}, Kapitel 3.

\begin{defi}[Tangentialbündel]\label{Tangentialvektor}
Sei $B_e(S^1, \mathbb{R}^2)$ der Shape-space für den $\mathbb{R}^2$. Betrachte einen Repräsentant $c: S^1 \rightarrow \mathbb{R}^2$ eines Punktes in $B_e(S^1, \mathbb{R}^2)$, sowie das zugehörige äußere Normalenvektorfeld $n$ der mit $c$ identifizierten Form $\partial\Omega_2$. Dann gilt für den \textit{Tangentialraum} $T_cB_e$
\begin{align*}
	T_cB_e \cong \{h : h = \alpha n \text{ für } \alpha \in C^\infty(\Omega_2,\mathbb{R})\}.
\end{align*}

\end{defi}

Diese Darstellung gilt, da die Quotientenstruktur von $B_e$ die Isomorphie der Immersionen von $S^1$ nach $\mathbb{R}^2$ mit den $C^\infty$-Funktionen von $S^1$ nach $\mathbb{R}^2$ vererbt, für Details siehe \cite{shape_space}, Kapitel 3.
Somit ermöglicht diese isomorphe Darstellung es uns, Tangentialvektoren $v \in T_cB_e$ mit Hilfe von $C^\infty(\Omega_2, \mathbb{R})$-Funktionen zu beschreiben. Das nutzen wir aus, um auf $B_e$ eine geeignete riemannsche Metrik zu definieren.

\colorbox{red}{Diagramm ??}

Es gibt verschieden Möglichkeiten riemannsche Metriken auf dem Raum $B_e$ zu definieren, je nachdem auf welche künftige Anwendung man abziehlt. Laut \cite{shape_space} scheint eine Sobolev-Metrik, definiert mittels des Laplace-Beltrami-Operators, natürlich zu erscheinen. Der Nachteil ist, das erheblicher Rechenaufwand beim Ermitteln des Gradienten aus einer Formableitung entsteht. Aus diesem Grund führen die Autoren von \cite{bfgs1} eine riemannsche Metrik auf Grundlage der sogenannten Dirichlet-zu-Neumann Abbildung ein, weshalb wir uns Ausführungen zu Sobolev-Metriken an dieser Stelle sparen, und verweisen für diese auf \cite{bfgs1} und \cite{shape_space}. Im Folgenden führen wir eine sogenannte Stekolov-Poincaré-Metrik ein, und verweisen für die hierzu nötigen Grundlagen bei Differentialgleichungen und Sobolev-Slobodeckij-Räumen auf \colorbox{red}{REF SLOBODECKIJ UND PDE}. Zunächst definieren wir die nötigen Abbildungen, vgl. \cite{bfgs1}.

\begin{defi}[Verallgemeinerte Spurabbildung]\label{Sproperatoren}
Sei $\Omega \subset \mathbb{R}^n$ eine beschränktes, offenes Gebiet. Sei $\Omega_2 \subset \Omega$ zusammenhängend, offen und habe einen Lipschitzrand, und $\partial \Omega_2$ sei eine Form in diesem Gebiet. Dann heißt die Abbildung
\begin{align*}
	\gamma: H^{1}_0(\Omega, \mathbb{R}^n) \rightarrow H^{1/2}(\Omega, \mathbb{R}^n)\times H^{-1/2}(\Omega, \mathbb{R}^n) \\
	U \mapsto 
	\left(\begin{matrix}
	\gamma_0 U \\ \gamma_1 U
	\end{matrix}\right)
	:= \left(\begin{matrix}
	U_{\vert \partial\Omega_2} \\ \partial_n U_{\vert \partial\Omega_2}
	\end{matrix}\right),
\end{align*}
\textit{verallgemeinerte Spurabbildung}, wobei $\partial_n U_{\vert\partial\Omega_2}$ die Ableitung von $U$ auf der Form $\partial \Omega_2$ in Richtung des äußeren Normalenvektorfeldes $n$ ist. \colorbox{red}{vielleicht einfach die Standard notation...}
\end{defi}

Wir erinnern an dieser Stelle, das diese Abbildung wohldefiniert ist, siehe \colorbox{red}{REFERENZ SPURSÄTZE}. Nun geben wir uns eine symmetrische, koerzive Bilinearform $a: H^1(\Omega, \mathbb{R}^n)\times H^1(\Omega, \mathbb{R}^n) \rightarrow \mathbb{R}$ vor. Diese werden wir später gemeinsam mit der zu definierenden Riemannschen Metrik verwenden, um aus gegebenen Formableitungen Gradienten zu konstruieren. Gegeben einer solchen Bilinearform $a$ definieren wir die zugehörigen Lösungsoperatoren zu folgendem Variationsproblem.

\colorbox{red}{Notation: alpha oder u ???!!! n den folgenden Definitionen}

\begin{defi}[Lösungsoperatoren]\label{Llsgsoperatoren}
Sei $\Omega\subset\mathbb{R}^n$ offen, zusammenhängend, beschränkt, und sei $\Omega_2\subset \Omega$ offen, zusammenhängend und habe einen $C^\infty$-Rand $\partial\Omega_2$.
Weiterhin sei $a: H^1(\Omega, \mathbb{R}^n)\times H^1(\Omega, \mathbb{R}^n) \rightarrow \mathbb{R}$ eine koerzive, symmetrische und \colorbox{red}{stetige}  Bilinearform. Dann heißt der Operator 
\begin{align*}
	E_N: H^{-1/2}(\partial\Omega_2, \mathbb{R}^n) &\rightarrow H^{1}_0(\Omega, \mathbb{R}^n) \\
	u &\mapsto U,
\end{align*}
\textit{Neumann-Lösungsoperator}, wobei $U$ die Lösung des Problems
\begin{align*}
	a(U,V) = \underset{\partial\Omega_2}{\int}u^T(\gamma_0 V)ds \quad \forall V \in H^1_0(\Omega,\mathbb{R}^n)
\end{align*}
ist, wobei $u^T(\gamma_0 V)$ eine duale Paarung meint. Außerdem heißt der Operator
\begin{align*}
	E_D: H^{1/2}(\partial\Omega_2, \mathbb{R}^n) &\rightarrow H^{1}_0(\Omega, \mathbb{R}^n) \\
	u &\mapsto U,
\end{align*}
\textit{Dirichlet-Lösungsoperator}, wobei $U$ die Lösung des Problems
\begin{align*}
	\begin{matrix} a(U,V) = 0 \\
	\text{unter } U_{\vert \partial\Omega_2} = u 
	\end{matrix} \quad\; \forall V \in H^1_0(\Omega,\mathbb{R}^n),
\end{align*}
ist.
\end{defi}

Wir fahren fort und definieren die projezierten Neumann-zu-Dirichlet und Dirichlet-zu-Neumann-Operatoren, welche wir zur konstruktion der Riemann'schen Metrik benötigen, siehe \cite{bfgs1}.

\colorbox{red}{sind die Namen richtig?, soll ich den unnötigen Operator nicht definieren?}

\begin{defi}[projezierte Randwertoperatoren]\label{Randoperatoren}
Seien die Voraussetzungen von \ref{Sproperatoren} und \ref{Llsgsoperatoren} gegeben. Dann heißt der Operator
\begin{align*}
	S^p: H^{-1/2}(\partial\Omega_2) &\rightarrow H^{-1/2}(\partial\Omega_2, \mathbb{R}^n) \rightarrow H^1_0(\Omega,\mathbb{R}^n) \rightarrow H^{1/2}(\partial\Omega_2, \mathbb{R}^n) \rightarrow H^{1/2}(\partial\Omega_2) \\
	\alpha &\mapsto n^T[\gamma_0 \circ E_N(\alpha \cdot n)]
\end{align*}
\textit{projezierter Neumann-zu-Dirichlet-Operator}, wobei $n^T$ eine duale Paarung meint.
\colorbox{red}{ist es richtig, wie linearformen und normale abbildungen miteinander verkettet werden. gibt es duale operatoren zu H(omega, Rn)?? ist oben  }
Der Operator
\begin{align*}
	T^p: H^{1/2}(\partial\Omega_2) &\rightarrow H^{1/2}(\partial\Omega_2,\mathbb{R}^n) \rightarrow H^1_0(\Omega,\mathbb{R}^n) \rightarrow H^{-1/2}(\partial\Omega_2,\mathbb{R}^n) \rightarrow H^{-1/2}(\partial\Omega_2) \\
	\alpha &\mapsto n^T[\gamma_1 \circ E_D(\alpha \cdot n)]
\end{align*}
heißt \textit{projezierter Dirichlet-zu-Neumann-Operator}.
\end{defi}


%Randwertoperatoren eigenschaften aus dem Paper zitieren, auf dortige Quelle verweisen.

Die hier definierten Operatoren sind nicht die klassischen Dirichlet-zu-Neumann-Operatoren, welche auch \textit{Stekolov-Poincaré-Operatoren} genannt werden, da diese nicht in projezierter Variante definiert werden. Wir haben diese so definiert, da wir die Identifikation der Tangentialvektoren, für welche die Riemann'sche Metrik definiert wird, mit Skalarfeldern $\alpha$ auf dem Rand $\partial\Omega_2$ nach Auswertung über äußere Normalenvektorfelder ausnutzen. Zur Erinnerung, siehe \ref{Tangentialvektor}. Was die Operatoren im wesentlichen tun, ist für gegebene Dirichlet- bzw. Neumann-Bedingungen die Lösung des durch die Bilinearform $a$ definierten Problems zu finden, und die entsprechenden anderen, automatisch konsistenten, Neumann- bzw. Dirichlet-Bedingungen zurückzugeben. Das heißt, für gegebene Dirichlet-Bedingungen liefert der projezierte Dirichlet-zu-Neumann-Operator die Neumann-Bedingungen, welche die selbe Lösung erzeugt, und vice versa.

Die klassischen Stekolov-Poincaré-Operatoren sind zueinander invers und vererben die Koerzivität, Stetigkeit und Symmetrie in dualer Paarung, \colorbox{red}{aufgrund der Koerzivität und Symmetrie der Bilinearform $a$,} siehe die Quellen bei \cite{bfgs1}, Def. 3.1. Die projezierten Operatoren besitzen weiterhin alle genannten Eigenschaften, bis auf die des Inversen. Um Rechenaufwand einzusparen, und Glättungseigenschaften auszunutzen, fällt die Wahl des Operators zur Definition des Skalarproduktes auf den Tangentialräumen auf $(S^p)^{-1}$, für Details, unter anderem zu spektraler Äquivalenz der Kanditaten, siehe \cite{bfgs1} und die dort genannten Quellen. Wir kommen nun zu unserem Ziel, eine Riemann'sche Metrik auf dem Shape-space für den $\mathbb{R}^2$ zu definieren, vgl. \cite{bfgs1}.

\colorbox{red}{Zitat Schulz und Jahr, for the credit :)}

\begin{defi}[Stekolov-Poincaré-Metrik]\label{Stek-Poi-metrik}
Seien die Voraussetzungen wie in \ref{Randoperatoren}. Dann heißt das Skalarprodukt
\begin{align*}
	g^S: H^{1/2}(\partial \Omega_2) \times H^{1/2}(\partial \Omega_2) \rightarrow \mathbb{R} \\
	(\alpha,\beta) \mapsto \langle \alpha, (S^p)^{-1}\beta \rangle = \underset{\partial \Omega_2}{\int} \alpha(s)\cdot((S^p)^{-1}\beta)(s)ds,
\end{align*}
\textit{Stekolov-Poincaré-Metrik}, wobei die Produkte auf der rechten Seite als duale Paarungen zu verstehen sind. 
\end{defi}

Das so definierte Skalarprodukt ist auf allgemeinen Sobolev-Slobodeckij-Räumen definiert, da Lösungen der Zustandsgleichung bei Auswertung auf dem Rand in der Regel Ordnung $1/2$ besitzen, siehe \colorbox{red}{Referenz auf PDE kapitel}. Diese Räume enthalten, wie wir in der Einführung zu Differentialgleichungen gezeigt haben, die $C^\infty$-Funktionen auf dem Rand. Somit ist das Skalarprodukt für Tangentialvektoren aller Formen aus $B_e(S^1, \mathbb{R}^2)$ wohldefiniert, da wir erneut Tangentialvektoren mit den Koeffizientenfeldern der äußeren Normalenvektorfelder identifizieren. Für den Beweis, dass $g^S$ eine Riemann'sche Metrik bildet, und $(B_e(S^1,\mathbb{R}^2),g^S)$ somit eine Riemann'sche Mannigfaltigkeit ist, siehe \colorbox{red}{zitiere Welker}.

Wir kommen nun zu dem Zusammenhang des in \colorbox{red}{zitiere shape calc} definierten Formkalküls und der soeben konstruierten Riemann'schen Mannigfaltigkeit $(B_e(S^1,\mathbb{R}^2),g^S)$.
Für die in dieser Arbeit genutzten Algorithmen ist die Gewinnung von Gradienten, welche wir Generierung von Deformationen nutzen wollen, aus der Formableitung eines Zielfunktionals von zentraler Bedeutung. Das Skalarprodukt $g^S$ bietet genau hierzu das geeignete Mittel.

\colorbox{red}{Definition von Formen mit Omega im shape kapitel, hier mit partialOmega2, irgendwie komisch und vllt unpassend, besser einheitliche notation}

\begin{defi}[Formgradient]\label{Formgradientdefi}
Seien die Voraussetzungen wie in \ref{Sproperatoren} und \ref{Llsgsoperatoren}.
Sei $\mathcal{J}$ ein formdifferenzierbares Formfunktional und die zugehörige Formableitung $D\mathcal{J}$. Betrachte die zu $c\in B_e(S^1,\mathbb{R}^2)$ gehörige Form $\partial\Omega_2$, mit Tangentialraum $T_cB_e$. Dann heißt der Tangentialvektor $h\in T_cB_e$ \textit{Formgradient von} $\mathcal{J}$ \textit{in c}, falls seine Darstellung $\alpha_h$ als Skalarvektorfeld, gemäß \ref{Tangentialvektor},

\colorbox{red}{stimmt hier für alle Cinfty V? eigentlich H10, aber das ersteres dicht liegt und gS bzw a stetig sind, egal?}

\begin{align}\label{Gradientengleichung}
	g^S(\alpha_h, \alpha_V) = D\mathcal{J}(\partial \Omega_2)[V] \quad \forall V\in C^\infty(\Omega,\mathbb{R}^2)
\end{align}
erfüllt, wobei $\alpha_V = \langle V_{\vert \partial\Omega_2}, n\rangle$ das Koeffizientenfeld des äußeren Normalenanteils $n$ von $V$ auf dem Rand $\partial \Omega_2$ ist.

\end{defi}

Die hier gemachte Definition ist als eine duale Repräsentation der Formableitung $D\mathcal{J}$ in dem Skalarprodukt $g^S$ zu sehen. Damit folgen wir nicht der typischen Definition eines gewöhnlichen Gradienten, wie diese oft in der elementaren Analysis stattfindet, sondern betrachten diese in Anlehnung an den  Riesz'schen Darstellungssatzes. Der Aufwand bis zur Definition des Formgradienten macht auch deutlich, wie wesentlich die Art des Gradienten vom zugrunde liegenden Skalarprodukt abhängt, ganz im Gegenteil zur Formableitung, für welche kein zugrunde liegendes Skalarprodukt benötigt wird. Somit ergeben sich für die selbe Formableitung, je nachdem welche Metrik man für den Shape-space verwendet, andere Gradienten und somit andere numerische Verfahren. Für eine Auswahl weiterer Alternativen, siehe \cite{shape_space}, Kapitel 3.2.

Es fällt weiterhin auf, dass die hier geforderte Gleichung \ref{Gradientengleichung} nicht in dualer Paarung mit Skalarfeldern, welche in die Ableitung $D\mathcal{J}$ einfließen, sondern in deren Koeffizientenfeldern der Normalenkomponente auf der Form berücksichtigt werden. Dies lässt sich mit dem Hadamard'schen Darstellungssatz begründen:
\begin{align*}
	D\mathcal{J}(\partial\Omega_2)[V] &= \underset{\partial\Omega_2}{\int}f(s)\langle V(s),n(s)\rangle ds \\
	&=\underset{\partial\Omega_2}{\int}f(s) \alpha_V(s)\langle n(s),n(s)\rangle ds \\
	&=\underset{\partial\Omega_2}{\int}f(s) \alpha_V(s) ds \\
	&= (f,\alpha_V)_{\mathcal{L}^2(\partial\Omega_2)}
\end{align*}
Damit wird klar, dass Vektorfelder $V\in C^\infty(\Omega,\mathbb{R}^2)$ mit gleichen Werten in äußerer Normalenrichtung $n$ auf $\partial\Omega_2$ auch den selben Wert bei Ableitung erhalten, und somit lediglich die Koeffizientenfelder $\alpha$ relevant sind. Die Identifikation mit diesen ist auch nötig, da wir das Skalarprodukt $g^S$ für gerade diese Funktionen definiert haben, und nicht bezüglich der echten Tangentialvektoren, welche Vektorfelder sind.

\colorbox{red}{Erklärung, warum das alles ok ist mit dem Koeffizientenfeld, und das Cinfty R2 nicht so stark ist, sondern nur Rand relevant wegen hadamard, dann überleitung als Satz für Darstellung mit bilinform a }

Mit diesem Zusammenhang lässt sich auch leicht der Bezug zu auf ganz $\Omega$ definierten Vektorfeldern $U,V$, und der Bilinearform $a$, welche $g^S$ zu Grunde liegt, beschreiben. Wir formulieren die Zusammenhänge aus \cite{bfgs1} für unsere Situation und Notation als Satz um, und geben einen Beweis. 

\colorbox{red}{vielleicht h = grad J nenne?}

\begin{theorem}[Formgradienten und Deformationsfelder]
Seien die Voraussetzungen wie in \ref{Formgradientdefi}. Sei $a$ eine koerzive, beschränkte, symmetrische Bilinearform, und $g^S$ die zugehörige Stekolov-Poincaré-Metrik. Weiterhin sei $h$ der zu einer Form $\partial\Omega_2$ und Formfunktional $\mathcal{J}$ gehörige Formgradient. Dann existiert ein zu $h$ gehöriges Vektorfeld $H \in H^1_0(\Omega, \mathbb{R}^n)$, so dass gilt
\begin{align}\label{zentraleDeformation}
	g^S(\alpha_h, \alpha_V) = D\mathcal{J}(\partial\Omega_2)[V] = a(H,V) \quad \forall C^\infty(\Omega,\mathbb{R}^2)
\end{align}
und, mit Notation aus \ref{Sproperatoren},
\begin{align*}
	(\gamma_0\circ H)^T n = \alpha_h.
\end{align*}
\end{theorem}

\colorbox{red}{ sicher das hier Omega = R2 sein kann?? muss ich nicht zuerst eine Hold-all-domain definieren.... weil sonst ja Randbedingungen keinen Sinn machen.. vllt ist auch auf Omega2 das H definiert? weil dirrandbedingunen ja partialOmega2 sind}

\begin{proof}
Seien die Voraussetzungen wie oben. Nach der zuvor geführten Rechnung gilt
\begin{align*}
	g^S(\alpha_h, \alpha_V) = (f,\alpha_V)_{\mathcal{L}^2(\partial\Omega_2)},
\end{align*}
wobei $f$ aus der Randdarstellung von $D\mathcal{J}$ mittels Hadamard'schem Darstellungssatz stammt. Verwendet man die Definition \ref{Stek-Poi-metrik} von $g^S$, so erhält man
\begin{align*}
	\underset{\partial\Omega_2}{\int} \alpha_h (S^p)^{-1}(\alpha_V)ds = 				\underset{\partial\Omega_2}{\int} f \alpha_V ds
\end{align*}
für beliebige Vektorfelder $V\in C^\infty(\Omega, \mathbb{R}^2)$. Wegen der Invertierbarkeit von $S^P$, welche wegen \colorbox{red}{Stetigkeit} und Koerzivität der Bilinearform $a$ und Regularität des Randes \colorbox{red}{ mit dem Lemma von Lax-Milgram,sicher auch für neumann??, REFERNZ} gilt, sowie der Symmetrie von $g^S$, folgt mit dem Fundamentallemma der Variationsrechnung
\begin{align*}
	S^p(f) = \alpha_h.
\end{align*}
Nun folgt mit der Definition von $S^p$, siehe \ref{Llsgsoperatoren}, und mit der \colorbox{red}{Stetigkeit} und Symmetrie von $a$, dass ein $H \in H^1_0(\Omega,\mathbb{R}^2)$ \colorbox{red}{checke ob wirklich auf Omega, oder nur Omega2} existiert, so dass gilt
\begin{align*}
	a(H,V) = \underset{\partial\Omega_2}{\int} f \alpha_V ds \quad \forall V\in C^\infty(\Omega,\mathbb{R}^2),
\end{align*}
woraus insgesamt die erste Gleichung \colorbox{red}{vllt ref? label?} folgt. Die zweite Gleichung folgt direkt aus der Definition des projezierten Operators $S^p$ , siehe \ref{Randoperatoren}, und des Neumann-Lösungsoperators $E_N$, denn
\begin{align*}
	\alpha_h = S^p(f) = n^T(\gamma_0\circ E_N(f\cdot n)) = n^T(\gamma_0 \circ H)
\end{align*}
\end{proof}

Mit diesem Resultat haben wir nun mehrere Möglichkeiten, aus gegebener Formableitung $D\mathcal{J}$ eine Deformation einer Form $\partial\Omega_2$ zu erzeugen. Zum einen besteht die Möglichkeit, auf dem Rand $\partial\Omega_2$ zu agieren, indem man ein Normalenvektorfeld $h = \alpha_h \cdot n$ auf diesem mittels des Variationsproblems \ref{zentraleDeformation} auf Basis der linken Gleichheit erzeugt. Zu beachten ist, dass die so erzeugte Deformation lediglich auf dem Rand definiert ist, womit dann in der Anwendung das Gitter im Inneren und Äußeren nicht bewegt wird. Aus diesem Grund bezeichnen wir diese Art der Deformationsgewinnung \textit{Randformulierung}. Die andere Variante ist, eine Deformation auf dem gesamten Gebiet $\Omega$ zu gewinnen, indem man das Variationsproblem \ref{zentraleDeformation} auf Basis der rechten Gleichung mittels der Bilinearform 
$a$ zu erzeugen. Im Gegensatz zur ersten Variante können hier potentiell alle Punkte des Gitters verschoben werden, trotz dessen, dass lediglich die Randpunkte zur Änderung des Zielfunktionals beitragen. Diese Variante bezeichnen wir als \textit{Volumenformulierung}, angelehnt an die Arten der Darstellung der Formableitung \colorbox{red}{REFERENZ Kapitel}. Beide Varianten verwenden als zur Erzeugung des Gradienten die Ableitungsinformation, welche physikalische als Kraft interpretierbar ist. Wählt man als Beispiel für die Bilinearform $a$ die lineare Elastizitätsgleichung, so wird diese Interpretation noch deutlicher. Genau diese Bilinearform werden wir in der später \colorbox{red}{wirklich später oder wann? lage anschauen, wo Definiere ich mal diese lineare Elastizität? vllt als beispiel einer bilinearform direkt nach Definition?} folgenden praktischen Implementierung wählen, um in Volumenformulierung Formgradienten zu erzeugen.

Wir erwähnen an dieser Stelle noch, dass die durch das Variationsproblem \ref{zentraleDeformation} erzeugte Deformationen $h$ im Allgemeinen nicht in $C^\infty(\Omega,\mathbb{R}^2)$ sind, siehe \cite{bfgs1}. Dies liegt daran, dass im Allgemeinen je nach Wahl der Bilinearform $a$, welche den Operator $S^p$ und somit das Skalarprodukt $g^S$ erzeugt, sowie der rechten Seite der Gleichung und der Regularität des Gebietes auf der diese definiert sind, lediglich eine Lösung in $H^1_0(\Omega,\mathbb{R}^2)$ existiert. Aus diesem Grunde ist nach unserer Definition \ref{Tangentialvektor} $h$ nicht immer Element des Tangentialraums $T_cB_e$, was Probleme theoretischer Natur macht. Unter anderem deshalb besteht an dieser Stelle der Bedarf eines allgemeineren Formraumes. Beispielsweise wäre eine Möglichkeit, Formen mit $H^{1/2}$-Rändern zuzulassen, was in \cite{shape_space}, Kapitel 7, kurz erläutert wird. Hierbei entstehen allerdings neue Schwierigkeiten theoretischer Natur, welche noch nicht völlig erforscht sind. Für eine Einführung in diese Thematik und zugehörige Konzepte verweisen wir auf \cite{diffeology}.

Da wir nun mit \ref{zentraleDeformation} verstanden haben, wie Formgradienten mit Hilfe von Metriken $g^S$ und Bilinearformen $a$ erzeugt werden können, möchten wir für dieses ein Beispiel angeben. Die Wahl einer solchen Bilinearform $a$, und damit die einer Metrik $g^S$, ist in der Tat nicht trivial, und mehrere Möglichkeiten mit unterschiedlichen Eigenschaften bestehen hier. Die Wahl hängt unter anderem davon ab, welche \colorbox{red}{Ordnung der Hesse-Operator des betrachteten Problems hat.} Eine mögliche Wahl hierzu, wäre die zur schwachen Formulierung der \textit{biharmonischen Gleichung} gehörende Bilinearform \colorbox{red}{soll ich die konkret angeben? vllt mit Quelle?}. Wir werden für die Gewinnung von Formgradienten im Nachfolgenden die lineare Elastizitätsgleichung verwenden, welche wir nun einführen, wobei wir uns an \cite{bfgs1} und \cite{bfgs2} halten. \colorbox{red}{auf beliebigem gebiet Omega oder auf (0,1)2? und Form dazu definieren?}

\begin{defi}[Lineare Elastizitätsgleichung]
	Betrachte das Gebiet $(0,1)^2 \subset \mathbb{R}^2$. Sei $f_{elas}: (0,1)^2 \rightarrow \mathbb{R}$ eine Funktion. Dann heißt die Differentialgleichung
	\begin{equation}\label{linelas}
		\begin{aligned}
		\text{div}(\sigma) &= f_{elas} \quad \text{in } (0,1)^2 \\
		U &= 0 \quad \hspace{0.2cm} \text{auf } \partial([0,1]^2)
		\end{aligned}
	\end{equation}	 
	\colorbox{red}{mit,}
	\begin{align*}
		\sigma &:= \lambda_{elas} \text{Tr}(\epsilon)I + 2\mu_{elas}\epsilon \\
		\epsilon &:= \frac{1}{2}(\nabla U + \nabla U^T),
	\end{align*}
	\textit{lineare Elastizitätsgleichung} in starker Formulierung, wobei $\text{Tr}(\epsilon)$ die Spur der Matrix $\epsilon$ ist, und $\lambda_{elas} \in \mathbb{R}$, sowie $\mu_{elas} \in [0,\infty)$, die sogenannten \textit{Lamé-Parameter} sind. $\sigma$ wird als Dehnungs-, $\epsilon$ als Spannungstensor bezeichnet. \colorbox{red}{brauche ich das mit dem young modul und poisson zahl unbedingt? oder sollte ich vollständig sein, obwohl wir diese ja eigentlich nicht gebrauchen}
\end{defi}

Die Lösung $U: \Omega \rightarrow \mathbb{R}^2$ in dieser Differentialgleichung lässt sich als \colorbox{red}{physikalische} Deformation auf dem Gebiet $\Omega$ auffassen, \colorbox{red}{wobei $f_{elas}$ sich als physikalische Kraft interpretiert werden kann}. 

\colorbox{red}{LOKAL VARIIERENDE LAME-PARAMETER SIND IMPLEMENTIERT. SOLL ICH DIESE BENUTZEN? FALLS JA, ERKLÄRE DIES HIER}

Die Lamé-Parameter $\lambda_{elas}, \epsilon_{elas}$ besitzen hier keine physikalische Bedeutung, jedoch lassen haben diese Einfluss auf die Gitterdeformation, indem sie indirekt die Schrittweite steuern. Sie sind mit Hilfe des sogenannten \textit{Young'schen Elastizitätsmoduls} $E$ und der \textit{Poissonzahl} $\nu$ durch
\begin{align*}
	\lambda_{elas} = \frac{\nu E}{(1+\nu)(1-2\nu)}, \; 
	\epsilon_{elas} = \frac{E}{2(1+\nu)}
\end{align*}
darstellbar. Das Elastizitätsmodul $E$ lässt sich als Steifigkeit des Materials interpretieren. Die Poissonzahl $\nu$ gibt an, in welchem Verhältniss sich das einen Gitterpunkt umgebende Gitter ausdehnt, falls dieser Gitterpunkt in eine Richtung verschoben wird. Insgesamt lassen also die Lamé-Parameter durch ihre Wahl die Möglichkeit einer Art Schrittweitensteuerung zu. Im weiteren Verlauf dieser Arbeit wählen wir $\lambda_{elas} = 0$.

Möchte man nun mit Hilfe der linearen Elastizitätsgleichung auf Basis von Theorem \ref{zentraleDeformation} einen Formgradienten bestimmen, so besitzt man zwei Möglichkeiten. Zum einen lässt sich der Gradient mittels der Randformulierung der Formableitung $D\mathcal{J}$ bilden. Hierzu wird eine weitere Dirichlet-Randbedinungung bei der lineare Elastizitätsgleichung \ref{zentraleDeformation}, welche den Formgradienten bezüglich einer Sobolevmetrik auf der Form $\partial\Omega_2$ repräsentiert gebildet, und $f_{elas}$ wird auch $0$ gesetzt. Für Details hierzu, siehe \cite{bfgs1}.
Als andere Variante lässt sich die Volumenformulierung der Formableitung $D\mathcal{J}$ verwenden. Hierzu assembliert man bei der linearen Elastizitätsgleichung \ref{linelas} die rechte Seite $f_{elas}$ als den Volumenanteil $D\mathcal{J}_{target}$ \colorbox{red}{referenz auf Volumenform anderes Kapitel}. Die Perimeter-Regularisierung, welche nur von der Form $\partial\Omega_2$ abhängt, wird mit Hilfe einer zusätzlichen von-Neumann-Randbedingung der Form
\begin{align*}
	\frac{\partial U}{\partial n} = f^{surf} \quad \text{auf } \partial\Omega_2
\end{align*}
berücksichtigt. Formuliert man nun die so erhaltene lineare Elastizitätsgleichung in schwacher Formulierung um und verwendet als rechte Seite \colorbox{red}{zitiere anders Kapitel Formableitung}, so erhält man
\begin{equation}\label{finalformgradient}
	\begin{aligned}
		a_{elas}(U,V) := \underset{(0,1)^2}{\int}\sigma(U):\epsilon(V) \;dx = D\mathcal{J}(\Omega_2)[V] \quad \forall V\in H^1_0((0,1)^2, \mathbb{R}^2).
	\end{aligned}
\end{equation}
\ref{finalformgradient} ermöglicht nun bei relativ leichter Assemblierung die Berechnung eines Formgradienten durch lösen einer aus der linearen Elastizitätsgleichung erzeugten Variationsproblems, wobei wir die Rechtfertigung hierfür wie bei der Herleitung erwähnt in \ref{zentraleDeformation} finden. Wir werden für die praktische Implementierung \ref{finalformgradient} verwenden, wobei die Randformulierung prinzipiell Alternative zur Verfügung stände. 

\colorbox{red}{vllt. Bereiche trennen, evlt unterabschnitte?}
\subsection{Quasi-Newton-Verfahren}

\colorbox{blue}{definiere ineare, quad, und superlineare konvergenz, dazu noch bilder von typischen konvergenzgraphiken}


Nun besitzen wir alle theoretischen Hintergründe aus dem Bereich der Formoptimierung, um auf Ableitungen basierte Optimierungsverfahren einzuführen. Im Rahmen dieser Arbeit konzentrieren wir uns auf das sogenannte \textit{Limited-Memory-Broyden-Fletcher-Goldfarb-Shanno-Verfahren (L-BFGS-Verfahren)}. Dieses Verfahren ist ein sogenanntes \textit{Quasi-Newton-Verfahren}, welche wir im Folgenden nach \cite{Nocedal} erläutern möchten. Bevor wir dies tun, geben wir noch Definitionen von Konvergenzgeschwindigkeiten numerischer Optimierungsmethoden an, vgl. \cite{Nocedal}, Appendix A2. \colorbox{red}{schaue, ob nicht problem mit formuliert werden muss, denke so ist es aber übersichtlicher, dann noch das mit der beliebigen Norm klären}

\begin{defi}[Konvergenzraten]
	Betrachte ein Minimierungsproblem, wobei $x^*$ eine optimale Lösung ist. Sei $\{x_n\}_{n\in\mathbb{N}}$ eine Folge mit $x_n \rightarrow x^*$ in geeignetem Sinne. Dann heißt die Folge
	\begin{itemize}
		\item[i)] \textit{linear konvergent}, falls ein $c\in (0,1)$ existiert, mit
		\begin{equation}
			\frac{\vert\vert x_{n+1} - x^*\vert\vert}{\vert\vert x_n - x^* \vert\vert} \leq c \quad \text{für n hinreichend groß,} 
		\end{equation}
		\item[ii)]	\textit{superlinear konvergent}, falls gilt		
		\begin{equation}
		\begin{aligned}
		\hspace{-4.6cm}\underset{n \rightarrow \infty}{\lim} \frac{\vert\vert x_{n+1} - x^*\vert\vert}{\vert\vert x_n - x^* \vert\vert} = 0,
		\end{aligned}
		\end{equation}
		\item[iii)] \textit{quadratisch konvergent}, falls ein $c\in (0,1)$ existiert, mit
		\begin{equation}
			\frac{\vert\vert x_{n+1} - x^*\vert\vert}{\vert\vert x_n - x^* \vert\vert^2} \leq c \quad \text{für n hinreichend groß}.
		\end{equation}	
	\end{itemize}

\end{defi}

\colorbox{red}{erklärung + evtl diagramme, damit man weiß, was typisch ist}
\colorbox{red}{Übergang besser, auch zu newton}


Bevor wir die Quasi-Newton- und Newton-Verfahren in Shape spaces diskutieren, beginnen wir mit der theoretisch gesicherten Betrachtung der Verfahren in endlich dimensionalen Vektorräumen. Das klassische Newton-Verfahren versucht, im Gegensatz zu einem Gradientenverfahren, auch Informationen zweiter Ordnung des Zielfunktionals in Form eines Hesseoperators $\text{Hess} \mathcal{J}$ bei der Bildung eines Schrittes miteinzubeziehen. Verwendet die übliche Notation im endlich-dimensionalen Fall, so geschieht dies über das Lösen des Problems
\begin{equation}\label{newtonfinite}
	\text{Hess} \mathcal{J} (x_k)\Delta x = - \nabla \mathcal{J}(x_k).
\end{equation}
\colorbox{red}{gefällt noch nicht ganz}
Verwendet man dieses Verfahren zur Lösung eines endlich-dimensionalen Optimierungsproblems mit geeigneter Schrittweitensteuerung, so besitzt das volle Newton-Verfahren bei geeigneten Voraussetzungen quadratische Konvergenz, siehe \cite{Nocedal}. Quasi-Newton-Verfahren ergeben sich nun aus dem Newton-Ansatz, indem man statt der Hessematrix $\text{Hess}\mathcal{J}(x_k)$ eine Approximation $B_k$ für diese verwendet. Hierzu gibt es eine Vielzahl von Möglichkeiten. Genannt seien hier unter anderem die \textit{Symmetric Rank 1 (SR1)} Updateformel und das \textit{DFP-Verfahren}, siehe etwa \cite{Nocedal}. Die BFGS-Update-Formeln für die Hessematrix und ihre Inverse, falls existent, sind im endlich-dimensionalen Fall wie folgt definiert, vgl. \cite{Nocedal}, 6.1.

\begin{defi}[BFGS-Updates (endl. Dim.)]\label{BFGS-updates}
	\colorbox{red}{soll ich vllt noch dein endl. dim. Optimierungsproblem hinschreiben? Dyadische Produkt wird später ersetzt, auch kennzeichnen, auch erwähnen das später Metriken statt der eukl skalarprodukte verwendet werden}	
	Sei $B_k$ die Approximation der Hessematrix $\text{Hess}\mathcal{J}(x_k)$, weiterhin seien 
	\begin{align*}
		s_k &:= x_{k+1} - x_k \\ y_k &:= \nabla \mathcal{J}(x_{k+1}) - \nabla \mathcal{J}(x_k) \\ \rho_k &:= \frac{1}{y_k^T s_k }.
	\end{align*}
	Dann ist der \textit{BFGS-Update} definiert durch
	\begin{equation}
		B_{k+1} := B_k - \frac{B_k (s_k s_k^T) B_k}{s_k^T B_k s_k} + \frac{y_k y_k^T}{y_k^T s_k}.
	\end{equation}
	Das Inverse der Matrix $B_{k+1}$ besitzt die Updateformel
	\begin{equation}
		B_{k+1}^{-1} := (I - \rho_k s_k y_k^T)B_k^{-1}(I - \rho_k y_k s_k^T) + \rho_k s_k s_k^T.
	\end{equation}
\end{defi}
In der Definition ist nicht klar, was die natürliche Wahl für ein $B_0$, beziehungsweise $B_0^{-1}$ ist. Hier gibt es mehrere Möglichkeiten, beispielsweise kann man eine mittels automatischem Differenzieren gewonnene Hesseapproximation als Start $B_0$ wählen. Alternativ kann man die skalierte Identität $\alpha I$ mit $\alpha \in [0,\infty)$ wählen, um eine positiv definite Startmatrix zu erhalten.

Diese Formeln sind sogenannte \textit{symmetric rank 2 Updates}, da diese eine symmetrische Approximation der Hessematrix mit Updates vom Rang 2 sind. Leitet man die Updates auf abstraktem Wege her, so bietet sich die Möglichkeit an, zuerst $B_{k+1}^{-1}$ zu definieren, und mit Hilfe der sogennanten Sherman–
Morrison–Woodbury Formel den Update für $B_{k+1}$ aus $B_{k+1}^{-1}$ herzuleiten. Wir geben an dieser Stelle genau diese abstrakte definierende Eigenschaft der BFGS-Approximation $B_{k+1}^{-1}$ an, vgl. \cite{Nocedal}, da wir in dieser eine mögliche Chance zur Verallgemeinerung einer Hesseapproximation im Shape Space sehen.

\begin{theorem}[Definierende Eigenschaft des BFGS-Updates]
		
	Es gelte die Notation aus \ref{BFGS-updates}. Betrachte das Optimierungsproblem
	\begin{equation}\label{Frobeniusproblem}
	\begin{aligned}
		\underset{H}{\min} \vert\vert H - B_k^{-1} \vert\vert _{WFrob} \\
		\text{s.t. } H^T = H \text{und } H y_k = s_k,
	\end{aligned}
	\end{equation}
	wobei $B_k^{-1}$ die in \ref{BFGS-updates} definierte Inverse des $k$'ten BFGS-Updates ist, und 

$\vert\vert \cdot \vert\vert_{WFrob}$ die gewichtete Frobeniusnorm ist, siehe \cite{Nocedal}, 6.1. Dann ist der BFGS-Update der Inversen $B_{k+1}^{-1}$ die eindeutige Lösung des Problems \ref{Frobeniusproblem}.
\end{theorem}
Wie man sieht, lässt sich die Inverse der BFGS-Approximation der Hessematrix als Lösung eines beschränktes Optimierungsproblems für Matrizen definieren. Die einschränkenden Bedingungen entstehen hierbei auf natürliche Weise. Zum einen beschreibt die erste Nebenbedingung lediglich die Forderung einer symmetrichen Approximation, die zweite Nebenbedingung lässt sich, unter Verwendung der eingeführten Notation aus \ref{BFGS-updates}, äquivalent umformen zu
\begin{equation}
	B_k (x_{k+1} - x_k) = \nabla \mathcal{J}(x_{k+1}) - \nabla \mathcal{J}(x_k),
\end{equation}
was bekannt ist als \textit{Sekantengleichung}. Diese ergibt sich als natürliche Forderung, was man direkt sieht, wenn man $B_k$ durch die eigentliche Hessematrix $\text{Hess}\mathcal{J}(x_k)$ ersetzt. \colorbox{red}{rly? :D} Um Existenz einer Inversen zu gewährleisten ist als Bedingung hinreichend, dass die Matrix $B_k$ positiv definit ist. Setzt man dies voraus, so ergibt sich aus der Sekantengleichung als notwendige Bedingung
\begin{equation}
	s_k^T y_k = s_k^T B_k s_k > 0.
\end{equation}
Diese sogenannte \textit{curvature condition} muss also notwendigerweise erfüllt sein, wenn man positive Definitheit von $B_k$ erhofft. Andererseits führt diese auch dazu, dass ein BFGS-Update-Schritt, angewandt auf eine positiv definite Matrix $B_k$ oder ihr Inverses $B_k^{-1}$, erneut eine positiv definite Matrix erzeugt. Trivialerweise ist die bei konvexen Problemen die curvature condition immer erfüllt. Im nicht-konvexen Fall ist es trotzdem möglich mit Hilfe von Line-search-Techniken, etwa der Wolfe oder starken Wolfe-Bedingungen, vgl. \cite{Nocedal}, die curvature condition zu erfüllen. Zu der Konvergenzgeschwindigkeit des BFGS-Verfahens in endlicher Dimension lässt sich sagen, dass unter Voraussetzungen, wie etwa Liptschitz-stetige Hessematrizen, superlineare Konvergenz vorhanden ist, siehe \cite{Nocedal}, Theorem 6.6.
Sind die genannten Bedingungen nicht erfüllt, so ist die Konvergenz des BFGS-Verfahrens nicht gewährleistet. Es fällt auf, dass man zur Berechnung eines BFGS-Updates die volle $nxn$-Matrix $B_k$ speichern muss, da diese in der Regel keine dünn-besetztheit aufweisen, siehe \cite{Nocedal}, 7.2. Da dies vor allem im Fall großer $n$, etwa bei feinen, höherdimensionalen Gittern in der Formoptimierung, beträchliche Kosten verursacht, bedient man sich der sogenannten \textit{Limited Memory} Variante der Verfahren. Hierzu wird eine Approximation an $B_k$ erzeugt, indem man eine vorgegebene Anzahl $l$ der letzten Vektoren, welche bei Erzeugung der letzten Updates verwendet wurden, benutzt und speichert. Dies spart Speicherkapazität auf dem Rechner. Die formale Definition der approximativen Update-Schritte findet sich in \cite{Nocedal}, 7.(19), welche wir hier nicht angeben, da wir diese, ohne die BFGS-Approximationen $B_k$ zuvor auf Shape spaces verallgemeinert zu haben, sowieso nicht verallgemeinern können. Stattdessen verwenden wir die sogenannte \cite{2-Schleifen-L-BFGS Rekusion}, welche wir später, siehe \colorbox{red}{cite später}, auf den Formfall unter Vermeidung der Operatoren $B_k$ verallgemeinern können.

Wir führen nun in analoger Weise zu dem klassischen Newton Verfahren von zuvor ein Lagrange-Newton-Verfahren in Falle der Formoptimierung ein, um anschließend mögliche Verallgemeinerungen des BFGS-Verfahrens auf den Formfall zu diskutieren.
Da wir in Formräumen keine kanonische Vektorraumstruktur besitzen, benötigt man zur Verallgemeinerung des Newton-Verfahrens auf diese zusätzliche Techniken.
Die Autoren von \cite{LagrangeNewton} liefern dafür einen Zugang unter Ausnutzung der Mannigfaltigkeitsstruktur, welche wir bereits zuvor in dieser Arbeit zur Konstruktion eines Formgradienten eingeführt haben. Hierzu konstruieren die Autoren auf Grundlage des Raums aller Formen eine neue Mannigfaltigkeit, welche im wesentlichen ein Produkt aus Bündeln von den Formen $\partial\Omega_2$ abhängiger Hilberträume, wie in \colorbox{red}{referenz als Beispiel wie in Kapitel zu Formableitung bei Lagrangefunktion}, und dem Shape space selber sind, siehe \cite{LagrangeNewton}, unter Remark 1.  Nun verwenden die Autoren Tangentialvektoren auf eben dieser Mannigfaltigkeit, um Richtungen zu gewinnen, mit derer Hilfe mittels der Exponentialabbildung auf dem Raum der Formen ein Optimierungsschritt definiert werden kann. Formal lässt sich dies wie folgt notieren, wobei $\zeta = (h_y, h_{\Omega_2}, h_p)$ ein Tangentialvektor der oben genannten Mannigfaltigkeit, von der Form analog zu \colorbox{red}{zitiere Lagrangefunktion}, ist:

\begin{itemize}
	\item[i)] Löse das Newton-Problem \\
	\begin{equation}\label{shapenewtonproblem}
	\text{Hess}\mathcal{L}(\zeta_k)\Delta \zeta = - \nabla \mathcal{L}(\zeta_k)
	\end{equation}
	\item[ii)] Berechne den Schritt mit einer Schrittlänge $\alpha_k$
	\begin{equation}
	\zeta_{k+1} := exp_{\zeta_k}(\alpha_k \Delta \zeta).
	\end{equation}
\end{itemize}
Wir haben das Lagrange-Newton-Verfahren im Shape-space ausformuliert, um auf die offenen Schwierigkeiten und Fragestellungen der Übertragung des Quasi-Newton-Ansatzes aus \colorbox{red}{...} aufmerksam zu machen. Da es sich bei 
\ref{shapenewtonproblem} um eine Operatorgleichung handelt, anders als bei \ref{newtonfinite}, welches ein LGS darstellt, ist nicht klar, welche Arten von Updates eine sinnvolle Verallgemeinerung der Updates \colorbox{red}{referenz bfgs updates} im endlich-dimensionalen Fall für die Approximation des Hesseoperators im Shape Space sind. \colorbox{red}{dies müsste ja auch von der Metrik abhängen, oder??},
\colorbox{green}{man könnte versuchen in analogie zu der Konstruktion von bfgs und dfp aus nocedal vorgehen. approxima gewinnen mittels bestapproximationen unter frobennius norm (bräuchte was ähnliches für mannigfaltigkeiten...) der Hesse durch mittels bedingungen eingeschränkte Kandidatenmengen. (ähnlich wie bei projektionssatz) Problem könnte nicht eindeutigkeit, da vllt keine konvexität, sein. weiterhin müsste man das konzept irgendwie auf mannigfaltigkeiten aufziehen, was lokal eigentlich gehen sollte, da tangentialräume die (konvexe) hilbertraumstruktur besitzen. fragt sich wie dies global mit der Mannigfaltigkeitsstruktur möglich wäre...}
\colorbox{green}{man muss auch die curvature Bedingung für bfgs in shape metriken übersetzen richtig? da in nocedal implizit das euklidische skalarprodukt verwendet wird}

Aufgrund der genannten Schwierigkeiten werden wir uns vorest mit der Übertragung der 2-Schleifen-L-BFGS Rekursion auf den Formfall begnügen. Hierzu haben die Autoren von \cite{bfgs1} den Algorithmus aus \cite{Nocedal}, 7.4, unter Verwendung des Zusammenhangs \ref{zentraleDeformation} und der dort vorkommenden Metrik $g^S$, sowie der Bilinearform $a$, angepasst. Zu beachten ist, dass hier die Tangentialvektoren Elemente verschiedener Tangentialräumen sind, weshalb diese noch zuerst in die richtigen Räume transportiert werden müssen. Für die differentialgeometrische Definition der Transporte $\mathcal{T}$, siehe etwa \cite{LeeDGEO} oder \cite{shape_space}, 2.3.1. Der klassische Algorithmus entsteht, wenn man statt der Metrik $g^S$ im endlich-dimensionalen Fall das euklidische Skalarprodukt verwendet, wobei keine Transporte von Tangentialvektoren anfallen. Es folgt die Definition nach \cite{bfgs1}, Kapitel 4.

\colorbox{red}{notation hj lieber zu grad (partial omega j) ???}
\colorbox{red}{ achtung: länge l oder länge m oder was genau}
\colorbox{red}{referenz zu den verwendeten Randauswertungen gamma aus vorigem Kapitel}

\begin{defi}[2-Schleifen-L-BFGS Rekursion im Formfall]
	Seien die Voraussetzungen wie aus \ref{zentraleDeformation}. Seien $h_i \in T_{partial\Omega_i}B_e$ Formgradienten der Formen $\partial\Omega_i$ mit ihren Darstellungen als Koeffizientenvektorfelder $\alpha_{h_i} \in H^{1/2}(\partial\Omega_i)$ nach \ref{Tangentialvektor} , sowie den zugehörigen Darstellungen $H_i \in H^1_0(\Omega, \mathbb{R}^2)$ auf dem ganzen Gebiet, nach \ref{zentraleDeformation}. Weiterhin seien $S_i \in H^1_0(\Omega, \mathbb{R}^2)$ Deformationsvektorfelder und $Y_i := H_{i+1} - \mathcal{T}_{S_i}H_i \in H^1_0(\Omega, \mathbb{R}^2)$ die entlang der Deformation $\mathcal{J}_{S_i}$ transportierte Differenz der Gradienten. Sei $m \in \mathbb{N}$ die Anzahl der gespeicherten Gradienten und Deformationen. Dann ist die \textit{2-Schleifen-L-BFGS Rekursion im Formfall} im Schritt $j$ gegeben durch 

\colorbox{red}{hier lieber alphas statt gamma verwenden?? also die definition wie wir sie zuvor gemacht haben}
\colorbox{red}{format: einrücken bei code wie in python}
\colorbox{red}{stimmt das mit den Vorzeichen hier: hatt ja den Fehler}

\begin{align*}
	\rho_j \leftarrow g^S((\gamma_0 Y_j)^Tn, (\gamma_0 S_j)^Tn)^{-1} = a(Y_j, S_j)^{-1} \\
		q \leftarrow H_j \\
	\textbf{for } i = j - 1, \dots, j - m \textbf{ do} \\
		S_i \leftarrow \mathcal{T}_q S_i \\
		Y_i \leftarrow \mathcal{T}_q Y_i \\
		\alpha_i \leftarrow \rho_i g^S((\gamma_0 S_i)^Tn, (\gamma_0 q)^T n) = \rho_i a(S_i, q) \\
				q \leftarrow q - \alpha_i Y_i \\
	\textbf{end for} \\
	q \leftarrow \frac{g^S((\gamma_0 Y_{j-1})^Tn, (\gamma_0 S_{j-1})^Tn)}{g^S((\gamma_0 Y_{j-1})^Tn, (\gamma_0 Y_{j-1})^Tn)}q = \frac{a(Y_{j-1}, S_{j-1})}{a(Y_{j-1}, Y_{j-1})}q \\	
	\textbf{for } i = j - m, \dots, j - 1 \textbf{ do} \\
		\beta_i \leftarrow \rho_i g^S((\gamma_0 Y_i)^Tn, (\gamma_0 q)^Tn) = \rho_i a(Y_i, q) \\
		q \leftarrow q + (\alpha_i - \beta_i)S_i \\
		\textbf{end do.}
\end{align*}
	Dann lässt sich das erzeugte Vektorfeld als Deformation $S_j := q$ verwenden. \colorbox{red}{vorzeichen!}
\end{defi}

\colorbox{red}{mache noch die hier benutzte vereinfachung der Transporte, rede kurz über transportgleichungen und lösung für geodätische, vllt mit Quelle aus einem Dgeo buch}

%Transporte!!!! und exponentialabbildung

\colorbox{red}{Erklärung}


\newpage
\nocite{*}
\bibliographystyle{plain}
\bibliography{papers}

\end{document}